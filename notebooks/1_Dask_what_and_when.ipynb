{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa397203",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dask/dask/main/docs/source/images/dask_horizontal.svg\"\n",
    "     width=\"60%\"\n",
    "     alt=\"Dask logo\\\" />\n",
    "\n",
    "\n",
    "# Basic Dask Concepts & When to Use Dask? \n",
    "\n",
    "\n",
    "If you've heard of Dask before, maybe you have a sense of how to answer these questions. If you haven't heard of Dask before and want to know what it is and when/if you should use it, then you are in the right place! :)\n",
    "\n",
    "Before we give a short overview and attempt to answer these questions, we strongly recommend you to check the amazing documentation that the Dask community has in place. \n",
    "\n",
    "- Documentation: https://docs.dask.org\n",
    "\n",
    "Contribute to the project:\n",
    "\n",
    "-  Github: https://github.com/dask/dask\n",
    "\n",
    "Engage with the community:\n",
    "\n",
    "- Discourse: https://dask.discourse.group/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c317728",
   "metadata": {},
   "source": [
    "### What is Dask? \n",
    "\n",
    "Dask is a flexible library for parallel computing in Python, that follows the syntax of the PyData ecosystem. If you are familiar with Numpy, pandas and scikit-learn then think of Dask as their faster cousin. For example:\n",
    "\n",
    "```python\n",
    "import pandas as pd                   import dask.dataframe as dd\n",
    "df = pd.read_csv('2015-01-01.csv')    df = dd.read_csv('2015-*-*.csv')\n",
    "df.groupby(df.user_id).value.mean()   df.groupby(df.user_id).value.mean().compute()\n",
    "```\n",
    "\n",
    " Since they are all family, Dask allows you to scale your existing workflows with a small amount of changes. Dask enables you to accelerate computations and perform those that don't fit in memory. It works in your laptop but it also scales out to large clusters while providing a dashboard with great diagnostic tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d4db3",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dask/dask/main/docs/source/images/dask-overview.svg\" \n",
    "     width=\"100%\"\n",
    "     alt=\"Dask overview\\\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179dd2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2022.6.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 192 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from dask) (0.11.2)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from dask) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from dask) (2022.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from packaging>=20.0->dask) (2.4.7)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: locket, partd, cloudpickle, dask\n",
      "Successfully installed cloudpickle-2.1.0 dask-2022.6.0 locket-1.0.0 partd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8359e2",
   "metadata": {},
   "source": [
    "### Dask Concepts: Client, Scheduler and Workers \n",
    "\n",
    "- **Client**: The user-facing entry point for cluster users. In other words, the client lives where your python code lives, and it communicates to the scheduler, passing along the tasks to be executed.\n",
    "- **Scheduler**: The task manager, it sends the tasks to the workers.\n",
    "- **Workers**: The ones that compute the tasks.\n",
    "\n",
    "Note: The Scheduler and the Workers are on the same network, they could live in your laptop or on a separate cluster\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/coiled/pydata-global-dask/master/images/dask-cluster.svg\"\n",
    "     width=\"75%\"\n",
    "     alt=\"Dask cluster\\\">\n",
    "     \n",
    "Or to go back to our barn-raising analogy, these are the main components of your parallel 'building' project:\n",
    "\n",
    "![](images/barn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d7794",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When to use Dask?\n",
    "\n",
    "Before trying to use Dask, there are some questions to determine if Dask might be suitable for you. \n",
    "    \n",
    "**Bottom Left:** You don't need Dask.    \n",
    "**Elsewhere:** Dask fair game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09496b-9b87-4a71-ba37-f038339c1254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/dask-zones.gif\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"images/dask-zones.gif\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf874d-0cec-41d8-a393-4c29739a2aec",
   "metadata": {},
   "source": [
    "This also means:\n",
    "\n",
    "## Don't use Dask if you don't need to!\n",
    "Distributed computing brings a lot of additional complexity into the mix and will **incur overhead**. If your dataset and computations fit comfortably within your local resources **this overhead will may be larger than the performance gain** you'll get by using Dask. In that case, stick with non-distributed libraries like pandas, numpy and scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e0e2c-de2d-4299-835f-c47542af8fac",
   "metadata": {},
   "source": [
    "## Dask Best Practices\n",
    "\n",
    "Transitioning to distributed computing comes with a learning curve because we're introducing multiple levels of additional complexity. That's why we the Dask team has built Best Practice guides that will make the process smoother. We will go over some of these topics but we want to leave here these links for future reference:\n",
    "\n",
    "- Are you working with arrays? Check this [array best practices](https://docs.dask.org/en/latest/array-best-practices.html)\n",
    "- Dealing with DataFrames? Check this [DataFrames best practices](https://docs.dask.org/en/latest/dataframe-best-practices.html)\n",
    "- Are you trying to accelerate your code using `delayed`? Check this [delayed best practices](https://docs.dask.org/en/latest/delayed-best-practices.html)\n",
    "- For overall good practices check [Dask good practices](https://docs.dask.org/en/latest/best-practices.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50907f",
   "metadata": {},
   "source": [
    "## Extra learning material:\n",
    "\n",
    "1. What is Dask? https://coiled.io/blog/what-is-dask/ \n",
    "2. Self-paced Dask-Tutorial: https://tutorial.dask.org/\n",
    "3. Dask training by Coiled: [Scaling Python with Dask](https://coiled.io/course/scaling-python-with-dask/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pydatalondon2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6a19c996a27d3bf996916365ad2336703eb6dad2b2633101ec37e82813581f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
